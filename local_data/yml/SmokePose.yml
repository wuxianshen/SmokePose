use_gpu: true
log_iter: 50
save_dir: output
snapshot_epoch: 1
#weights: ../local_data/models/trained/hrhrnet_135410/model_final.pdparams
epoch: 300
num_joints: &num_joints 2
input_size: &input_size 512
train_height: &train_height 512
train_width: &train_width 512
trainsize: &trainsize [*train_width, *train_height]
hm_size_s4: &hm_size_s4 128
hm_size_s8: &hm_size_s8 64
max_people: &max_people 1
metric: COCO
IouType: keypoints
num_classes: 1


#####model
architecture: StackFormer
#pretrain_weights: 'D:\\File\\Share\\0\\models\\models\\pre-train\\stack_former\\148817\\stack_former_seg_pretrain_148817.pdparams'
#pretrain_weights: 'D:\\Projects\\Python\\smoke_segmentation\\PaddleSeg-Packages\\paddleseg_v24\\output\\best_model\\model.pdparams'

StackFormer:
  model_level: 0
  former_head: StackFormerHead
  post_process: HRNetPostProcess
  loss: MultiHmMSELoss

HRNetPostProcess:
  use_dark: False

StackFormerHead:
  num_classes: 2
  embed_dim: 256
  out_chans: [256, 128, 64]

MultiHmMSELoss:
  hm_stride_list: [4, 8]
  hm_weights: [0.7, 0.3]


#####optimizer
LearningRate:
  base_lr: 0.001
  schedulers:
  - !PiecewiseDecay
    milestones: [200, 260]
    gamma: 0.1
  - !LinearWarmup
    start_factor: 0.001
    steps: 1000

OptimizerBuilder:
  optimizer:
    type: Adam
  regularizer: None

#####data
TrainDataset:
  !KeypointBottomUpCocoDataset
    image_dir: images
    anno_path: coco_jsons/train_coco.json
    dataset_dir: 'D:\\Research\\00_Dataset\\smoke_keypoint\\V1\\aug\\'
    num_joints: *num_joints

EvalDataset:
  !KeypointBottomUpCocoDataset
    image_dir: images
    anno_path: coco_jsons/valid_coco.json
    dataset_dir: 'D:\\Research\\00_Dataset\\smoke_keypoint\\V1\\aug\\'
    num_joints: *num_joints
    test_mode: true

TestDataset:
  !ImageFolder
    anno_path: dataset/coco/keypoint_imagelist.txt

worker_num: 8
global_mean: &global_mean [0.3816, 0.3884, 0.3934]
global_std: &global_std [0.2800, 0.2813, 0.2894]
TrainReader:
  sample_transforms:
    - RandomAffine:
        max_degree: 0
        scale: [ 1.0, 1.0 ]
        max_shift: 0.0
        trainsize: *input_size
        hmsize: [ *hm_size_s4, *hm_size_s8 ]
    - ToHeatmaps:
        num_joints: *num_joints
        hmsize: [ *hm_size_s4, *hm_size_s8 ]
        sigma: 2
    - SKPMultiHmGenerator:
        kp_num: 2
        img_size: *input_size
        hm_stride_list: [4, 8]
    - TagGenerate:
        num_joints: *num_joints
        max_people: *max_people
    - NormalizePermute:
        mean: *global_mean
        std: *global_std
  batch_size: 16
  shuffle: true
  drop_last: true
  use_shared_memory: true

EvalReader:
  sample_transforms:
    - EvalAffine:
        size: *input_size
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: 1

TestReader:
  sample_transforms:
    - Decode: {}
    - EvalAffine:
        size: *input_size
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: 1
